{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Categorization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N__JG6lAbvNK"
      },
      "source": [
        "# preparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PrYLLmlc-8My",
        "outputId": "20c3bd93-3351-43ef-a6d5-3ff1ae47d5ae"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googledrivedownloader in /usr/local/lib/python3.7/dist-packages (0.4)\n",
            "Downloading 1HGDbDVoQXL50lJrrc4K77AOwmOF2b-Cc into /content/data.json... Done.\n",
            "Unzipping..."
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/google_drive_downloader/google_drive_downloader.py:78: UserWarning: Ignoring `unzip` since \"1HGDbDVoQXL50lJrrc4K77AOwmOF2b-Cc\" does not look like a valid zip file\n",
            "  warnings.warn('Ignoring `unzip` since \"{}\" does not look like a valid zip file'.format(file_id))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yCwRIKkKCvsW"
      },
      "source": [
        "# from google.colab import files\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3B5VWSSTb-uf",
        "outputId": "ff0a16e1-0050-4644-b7e4-0f293679cc21"
      },
      "source": [
        "!pip install transformers\n",
        "!pip -q install clean-text[gpl]\n",
        "!pip install bs4\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.12.5-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Collecting huggingface-hub<1.0,>=0.1.0\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 6.2 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (596 kB)\n",
            "\u001b[K     |████████████████████████████████| 596 kB 47.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 37.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.6.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Installing collected packages: pyyaml, tokenizers, sacremoses, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.1.2 pyyaml-6.0 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.12.5\n",
            "\u001b[K     |████████████████████████████████| 170 kB 6.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 64 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 235 kB 31.2 MB/s \n",
            "\u001b[?25h  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: bs4 in /usr/local/lib/python3.7/dist-packages (0.0.1)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.7/dist-packages (from bs4) (4.6.3)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 5.4 MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.96\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkgUcN2Leu4l"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fR3vbcRvb-vU"
      },
      "source": [
        "import json\n",
        "file = open(\"data.json\", encoding=\"utf8\")\n",
        "file = json.load(file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLaLtaaNeUx2"
      },
      "source": [
        "data = []\n",
        "for block in file:\n",
        "  if len(block['Categories']) > 0:\n",
        "    for i in range(len(block['Categories'])):\n",
        "      data.append((block['Categories'][i]['Sentence'], block['Categories'], '', 0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "0_d4AiEfemhb",
        "outputId": "cd689499-8057-4438-f0bf-8cae73391cda"
      },
      "source": [
        "df = pd.DataFrame(data, columns = ['Comment', 'Categories', 'Category', 'Labels'])\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Categories</th>\n",
              "      <th>Category</th>\n",
              "      <th>Labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>واقعا عالی و ب موقع رسید.</td>\n",
              "      <td>[{'Id': 8362, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد.</td>\n",
              "      <td>[{'Id': 8360, 'Phrase': 'قیمت', 'Sentence': 'ق...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد.</td>\n",
              "      <td>[{'Id': 8360, 'Phrase': 'قیمت', 'Sentence': 'ق...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "      <td>[{'Id': 8358, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "      <td>[{'Id': 8358, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5389</th>\n",
              "      <td>وبینار شش روزه در #ایسمینار برگزار کردیم عالی بود</td>\n",
              "      <td>[{'Id': 2723, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>از تیم ایسمینار راضی‌ام</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5391</th>\n",
              "      <td>پشتیبانی خوب</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5392</th>\n",
              "      <td>سایت خوب</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5393</th>\n",
              "      <td>من ازتون خرید کردم واقعا عالین</td>\n",
              "      <td>[{'Id': 2718, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td></td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5394 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  ... Labels\n",
              "0                             واقعا عالی و ب موقع رسید.  ...      0\n",
              "1                   قیمتا خوب بود و سریع تحویل داده شد.  ...      0\n",
              "2                   قیمتا خوب بود و سریع تحویل داده شد.  ...      0\n",
              "3     واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...  ...      0\n",
              "4     واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...  ...      0\n",
              "...                                                 ...  ...    ...\n",
              "5389  وبینار شش روزه در #ایسمینار برگزار کردیم عالی بود  ...      0\n",
              "5390                            از تیم ایسمینار راضی‌ام  ...      0\n",
              "5391                                      پشتیبانی خوب   ...      0\n",
              "5392                                          سایت خوب   ...      0\n",
              "5393                     من ازتون خرید کردم واقعا عالین  ...      0\n",
              "\n",
              "[5394 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nNCEAQ3b-z8",
        "outputId": "6fd2aa4c-913e-46c4-cb5f-cf3fc1501ae6"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  for j in range(len(df['Categories'][i])):\n",
        "    if df['Categories'][i][j]['Phrase'] in [None,'']:\n",
        "      df['Category'][i] = 'بدون کتگوری'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['سلامت کالا','کیفیت کالا','ضمانت کالا','اصالت کالا','تنوع کالا ','کیفیت ',' کیفیت','کیفیت']:\n",
        "      df['Category'][i] = 'ضمانت،کیفیت،تنوع،مطابقت کالا'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['ارسال','بسته بندی','ارسال ']:\n",
        "      df['Category'][i] = 'ارسال'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['قیمت',' قیمت','تخفیفات','قی']:\n",
        "      df['Category'][i] = 'قیمت و تخفیفات'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['کاربری آسان','کارایی آسان','به روز بودن']:\n",
        "      df['Category'][i] = 'کاربری و کارایی'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['مرجوعی','بازگشت وجه']:\n",
        "      df['Category'][i] = 'مرجوعی و عودت وجه'\n",
        "    if df['Categories'][i][j]['Phrase'] in ['عمومی','خدمات']:\n",
        "      df['Category'][i] = 'خدمات - عمومی'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  app.launch_new_instance()\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if sys.path[0] == '':\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u9whhc3hbyNp"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7pKruMvCb6kz"
      },
      "source": [
        "import nltk\n",
        "from nltk import word_tokenize, sent_tokenize\n",
        "# from PersianStemmer import PersianStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "\n",
        "from cleantext import clean\n",
        "import codecs,re\n",
        "def arabic_to_farsi(text):\n",
        "    text = re.sub(r'[كﮑﮐﮏﮎﻜﻛﻚﻙ]', r'ک', text)\n",
        "    text = re.sub(r'[ىىىﻴﻢﻳﻲﻱﻰىىﻯي]', r'ی', text)\n",
        "    return text\n",
        "\n",
        "def cleaning(text):\n",
        "  text = str(text)\n",
        "  text = re.sub(r'#', ' ', text)\n",
        "  text = re.sub(r'_', ' ', text)\n",
        "  text = text.replace('\\u200c', ' ')\n",
        "  text = re.sub(r'([ا-ی])\\1{2,}', r'\\1', text) # bbb+ -> b at least 2 char\n",
        "  text = re.sub(r'[^\\w\\s]',' ',text)\n",
        "  text = re.sub(r'\\@\\w*', ' ', text)\n",
        "  text = re.sub(r'\\d+', ' ', text)\n",
        "  text = re.sub(r'$', ' ', text)\n",
        "  text = re.sub(r\"[a-zA-Z0-9]+\", \" \",text)\n",
        "  text = re.sub(r'<(.*?)>', ' ', text)\n",
        "  text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', ' ', text)\n",
        "  text=re.sub(r'[۰۱۲۳۴۵۶۷۸۹٠١١٢٣٤٥٦٧٧٨٨٩٩●]',' ',text)\n",
        "  text=re.sub(r'[\\·\\♦\\٭\\\\,\\^\\|\\˝\\٬\\’\\”\\‹\\▪\\○¼ç½éêüəıœ™Ááàäāćíłñū©ٰٔ]',' ',text)\n",
        "  text=re.sub(r'[ًٌٍَُِّْ]',' ',text)\n",
        "  text=re.sub(r'[]',r' ',text)\n",
        "  text=re.sub(r'[\\–\\—…°≈≠±≤≥\\−×÷√٪→←↔↑↓\\#\\٫]',u' ',text) \n",
        "  text=text.replace(u'•',u' ').replace(u'ˈ',u' ').replace(u'؛',u' ').replace(u'/',u' ').replace(u'ۀ',u'هٔ').replace(u\"﴿\",u' ').replace(u\"﴾\",u' ').replace(u\"'\",u' ').replace(u'\\\\',u' ').replace(u'[',u' ').replace(u']',u' ').replace(u'?',u' ').replace(u'؟',u' ').replace(u')',u' ').replace(u'_',u' ').replace(u'(u',u' ').replace(u'}',u' ').replace(u'{',u' ').replace(u'.',u' ').replace(u'>',u' ').replace(u'<',u' ')\n",
        "  text=text.replace(u'`',u' ').replace(u'\\t',u' ').replace(u'=',u' ').replace(u'»',u' ').replace(u'«',u' ').replace(u'~',u' ').replace(u'!',u' ').replace(u'@',u' ').replace(u'$',u' ').replace(u',u',u' ').replace(u'%',u' ').replace(u'،',u' ').replace(u'-',u' ').replace(u';',u' ').replace(u':',u' ').replace(u'*',u' ').replace(u'\"',u' ').replace(u'&',u' ').replace(u'#',u' ').replace(u'+',u' ')\n",
        "  text=re.sub(r'[\\n\\r]{2,}',u'\\n',text)\n",
        "  text = re.sub(u'(\\u202A|\\u202B|\\u202C|\\u202D|\\u202E|\\u200F|\\uFEFF|\\u2003|\\¬|\\­)',u'\\u200C', text)#حذف کارکترهای تغییرجهت\n",
        "  text = re.sub(u'‌{2,}', u'‌', text) # پشت‌سرهم\n",
        "  text = re.sub(u'‌(?![ئاآأإژزرذدوؤةبپتثجچحخسشصضطظعغفقکگلمنهیيًٌٍَُِّْٰٓٔ]|[\\u0900-\\u097F]|ֹ)', u'', text) # در پس\n",
        "  text = re.sub(u'(?<![ئبپتثجچحخسشصضطظعغفقکگلمنهیيًٌٍَُِّْٰٓٔ]|[\\u0900-\\u097F]|f|ֹ)‌', u'', text) # در پیش\n",
        "  text=text.replace(u'­',u' ').replace(u'­',u' ').replace(u'ـ',u' ').replace(u'ـ',u' ').replace(u'ـ',u' ').replace(u'ـ',u' ').replace(u'\u001b',u' ')\n",
        "  text=text.replace(u'\u001b',u' ')\n",
        "  text = re.sub(u'‌{2,}', u'‌', text) # پشت‌سرهم\n",
        "  text = re.sub(u'(\\u00A0)',u' ', text).replace(u'(',u' ').replace(u')',u' ')\n",
        "  text=text.replace(u'    ',u' ').replace(u'    ',u' ').replace(u'   ',u' ').replace(u'  ',u' ').replace(u'  ',u' ').replace(u'  ',u' ')\n",
        "  # text=arabic_to_farsi(text)\n",
        "  return text.strip()\n",
        "\n",
        "def remove_stopwords(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  persian_stopwords = StopWords\n",
        "\n",
        "  results = [w for w in tokens if w not in persian_stopwords and w not in string.punctuation]\n",
        "  \n",
        "  return ' '.join(results)\n",
        "\n",
        "def stemming(text):\n",
        "  tokens = word_tokenize(text)\n",
        "  persian_stemmer = Stemmer()\n",
        "\n",
        "  results = [persian_stemmer.stem(w) for w in tokens]\n",
        "\n",
        "  return ' '.join(results)\n",
        "\n",
        "def lemmatizing(text):\n",
        "  wordlist = []\n",
        "  lemmatizer = WordNetLemmatizer()\n",
        "  \n",
        "  sentences = sent_tokenize(text)\n",
        "\n",
        "  for sentence in sentences:\n",
        "        words=word_tokenize(sentence)\n",
        "        for word in words:\n",
        "            wordlist.append(lemmatizer.lemmatize(word))\n",
        "\n",
        "  return ' '.join(wordlist)\n",
        "\n",
        "def normalize(text):\n",
        "  # result = lemmatizing(text)\n",
        "  result = stemming(text)\n",
        "  result = remove_stopwords(result)\n",
        "\n",
        "  return result\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wLBBZAllb7bM"
      },
      "source": [
        "df['Clean_Body'] = df.Comment.apply(cleaning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMd7s8arb7b4"
      },
      "source": [
        "label_dict = {}\n",
        "labels = list(set(df.Category))\n",
        "for i in range(len(list(set(df.Category)))):\n",
        "  label_dict[labels[i]] = i"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HO7lyDTab7lv",
        "outputId": "eb230566-1df8-49da-90ec-ae1cc1ad03c9"
      },
      "source": [
        "for i in range(len(df)):\n",
        "  for label in labels:\n",
        "    if df['Category'][i] == label:\n",
        "      df['Labels'][i] = label_dict[label]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "cIMRcPdlszXR",
        "outputId": "f93bdd0a-518c-4f3e-8e96-7eaaac57739b"
      },
      "source": [
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Comment</th>\n",
              "      <th>Categories</th>\n",
              "      <th>Category</th>\n",
              "      <th>Labels</th>\n",
              "      <th>Clean_Body</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>واقعا عالی و ب موقع رسید.</td>\n",
              "      <td>[{'Id': 8362, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td>ارسال</td>\n",
              "      <td>1</td>\n",
              "      <td>واقعا عالی و ب موقع رسید</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد.</td>\n",
              "      <td>[{'Id': 8360, 'Phrase': 'قیمت', 'Sentence': 'ق...</td>\n",
              "      <td>ارسال</td>\n",
              "      <td>1</td>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد.</td>\n",
              "      <td>[{'Id': 8360, 'Phrase': 'قیمت', 'Sentence': 'ق...</td>\n",
              "      <td>ارسال</td>\n",
              "      <td>1</td>\n",
              "      <td>قیمتا خوب بود و سریع تحویل داده شد</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "      <td>[{'Id': 8358, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td>قیمت و تخفیفات</td>\n",
              "      <td>4</td>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "      <td>[{'Id': 8358, 'Phrase': 'ارسال', 'Sentence': '...</td>\n",
              "      <td>قیمت و تخفیفات</td>\n",
              "      <td>4</td>\n",
              "      <td>واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5389</th>\n",
              "      <td>وبینار شش روزه در #ایسمینار برگزار کردیم عالی بود</td>\n",
              "      <td>[{'Id': 2723, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td>خدمات - عمومی</td>\n",
              "      <td>5</td>\n",
              "      <td>وبینار شش روزه در ایسمینار برگزار کردیم عالی بود</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5390</th>\n",
              "      <td>از تیم ایسمینار راضی‌ام</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td>کاربری و کارایی</td>\n",
              "      <td>3</td>\n",
              "      <td>از تیم ایسمینار راضی ام</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5391</th>\n",
              "      <td>پشتیبانی خوب</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td>کاربری و کارایی</td>\n",
              "      <td>3</td>\n",
              "      <td>پشتیبانی خوب</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5392</th>\n",
              "      <td>سایت خوب</td>\n",
              "      <td>[{'Id': 2720, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td>کاربری و کارایی</td>\n",
              "      <td>3</td>\n",
              "      <td>سایت خوب</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5393</th>\n",
              "      <td>من ازتون خرید کردم واقعا عالین</td>\n",
              "      <td>[{'Id': 2718, 'Phrase': 'عمومی', 'Sentence': '...</td>\n",
              "      <td>خدمات - عمومی</td>\n",
              "      <td>5</td>\n",
              "      <td>من ازتون خرید کردم واقعا عالین</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5394 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Comment  ...                                         Clean_Body\n",
              "0                             واقعا عالی و ب موقع رسید.  ...                           واقعا عالی و ب موقع رسید\n",
              "1                   قیمتا خوب بود و سریع تحویل داده شد.  ...                 قیمتا خوب بود و سریع تحویل داده شد\n",
              "2                   قیمتا خوب بود و سریع تحویل داده شد.  ...                 قیمتا خوب بود و سریع تحویل داده شد\n",
              "3     واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...  ...  واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...\n",
              "4     واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...  ...  واقعا سایت عالی سریع مرسوله میرسونن قیمت ها عا...\n",
              "...                                                 ...  ...                                                ...\n",
              "5389  وبینار شش روزه در #ایسمینار برگزار کردیم عالی بود  ...   وبینار شش روزه در ایسمینار برگزار کردیم عالی بود\n",
              "5390                            از تیم ایسمینار راضی‌ام  ...                            از تیم ایسمینار راضی ام\n",
              "5391                                      پشتیبانی خوب   ...                                       پشتیبانی خوب\n",
              "5392                                          سایت خوب   ...                                           سایت خوب\n",
              "5393                     من ازتون خرید کردم واقعا عالین  ...                     من ازتون خرید کردم واقعا عالین\n",
              "\n",
              "[5394 rows x 5 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d5Y3XkPdb3US"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTPs_ojhccZ6"
      },
      "source": [
        "import time, sys\n",
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from IPython.display import clear_output\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class DigiMagDs(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "class TorchTrainer:\n",
        "    def __init__(self, model, train_dl, valid_dl, test_dl, optimizer, scheduler):\n",
        "        self.model = model\n",
        "        self.train_dl = train_dl\n",
        "        self.valid_dl = valid_dl\n",
        "        self.test_dl = test_dl\n",
        "        self.optimizer = optimizer\n",
        "        self.scheduler = scheduler\n",
        "        self.loss_history = []\n",
        "\n",
        "    def fit(self, num_epochs):\n",
        "        clear_output()\n",
        "        valid_acc = 0\n",
        "        for epoch in range(num_epochs):\n",
        "            print('Epoch %2d/%2d' % (epoch + 1, num_epochs))\n",
        "            print('-' * 20)\n",
        "            t0 = time.time()\n",
        "            train_acc = self.train_model()\n",
        "            valid_acc, _,_= self.valid_model()\n",
        "            time_elapsed = time.time() - t0\n",
        "            print('\\n Metrics: | train_acc: %.3f | valid_acc: %.3f |' % (train_acc[0], valid_acc[0]))\n",
        "            print('\\n  Epoch complete in: %.0fm %.0fs \\n' % (time_elapsed // 60, time_elapsed % 60))\n",
        "        return\n",
        "\n",
        "    def train_model(self):\n",
        "        self.model.train()\n",
        "        N = len(self.train_dl.dataset)\n",
        "        step = N // self.train_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        for i, batch in enumerate(self.train_dl):\n",
        "            self.optimizer.zero_grad()\n",
        "            # forward\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "            outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "            # loss\n",
        "            loss = outputs['loss']\n",
        "            # backward\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "            self.scheduler.step()\n",
        "            # statistics of model training and print\n",
        "            avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "            avg_acc += torch.sum(predictions == labels)\n",
        "            self.loss_history.append(avg_loss)\n",
        "            sys.stdout.flush()\n",
        "            sys.stdout.write(\"\\r  Train_Step: %d/%d | runing_loss: %.4f\" % (i + 1, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) / N\n",
        "\n",
        "    def valid_model(self):\n",
        "        print()\n",
        "        self.model.eval()\n",
        "        N = len(self.valid_dl.dataset)\n",
        "        step = N // self.valid_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        Predictions = []\n",
        "        Labels = []\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.valid_dl):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "                loss = outputs['loss']\n",
        "                avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "                avg_acc += torch.sum(predictions == labels)\n",
        "                Predictions = Predictions + predictions.tolist()\n",
        "                Labels = Labels + labels.tolist()\n",
        "                sys.stdout.flush()\n",
        "                sys.stdout.write(\"\\r  Valid_Step: %d/%d | runing_loss: %.4f\" % (i, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) /N ,Predictions,Labels\n",
        "\n",
        "    def test_model(self):\n",
        "        print()\n",
        "        self.model.eval()\n",
        "        N = len(self.test_dl.dataset)\n",
        "        step = N // self.test_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        Predictions = []\n",
        "        Labels = []\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.test_dl):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "                loss = outputs['loss']\n",
        "                avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "                avg_acc += torch.sum(predictions == labels)\n",
        "                Predictions = Predictions + predictions.tolist()\n",
        "                Labels = Labels + labels.tolist()\n",
        "                sys.stdout.flush()\n",
        "                sys.stdout.write(\"\\r  Valid_Step: %d/%d | runing_loss: %.4f\" % (i, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) /N ,Predictions,Labels\n",
        "\n",
        "    def test_model_probs(self):\n",
        "        print()\n",
        "        self.model.eval()\n",
        "        N = len(self.test_dl.dataset)\n",
        "        step = N // self.test_dl.batch_size\n",
        "        avg_loss = 0.0\n",
        "        avg_acc = 0.0\n",
        "        Predictions = []\n",
        "        Probabilities = []\n",
        "        Labels = []\n",
        "        with torch.no_grad():\n",
        "            for i, batch in enumerate(self.test_dl):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "                outputs = self.model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "                predictions = torch.argmax(outputs['logits'], dim=1)\n",
        "                probabilities = F.softmax(outputs['logits'], dim=-1)\n",
        "                loss = outputs['loss']\n",
        "                avg_loss = (avg_loss * i + loss) / (i + 1)\n",
        "                avg_acc += torch.sum(predictions == labels)\n",
        "                Predictions = Predictions + predictions.tolist()\n",
        "                probabilities = [max(x) for x in probabilities.tolist()]\n",
        "                Probabilities = Probabilities + probabilities\n",
        "                Labels = Labels + labels.tolist()\n",
        "                sys.stdout.flush()\n",
        "                sys.stdout.write(\"\\r  Valid_Step: %d/%d | runing_loss: %.4f\" % (i, step, avg_loss))\n",
        "\n",
        "        sys.stdout.flush()\n",
        "        return torch.tensor([avg_acc]) /N ,Probabilities,Labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZNDKi8Hp797"
      },
      "source": [
        "batch_size = 32\n",
        "max_len = 120\n",
        "class_number = len(list(set(df.Category)))\n",
        "RANDOM_SEED = 42\n",
        "model_name = \"HooshvareLab/albert-fa-zwnj-base-v2\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSSgnksbp7-2",
        "outputId": "bfc7a91d-d026-4b65-bd1d-e8ec5b51b38b"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_df,test_df = train_test_split(df, test_size=0.1, random_state=RANDOM_SEED,shuffle=True)\n",
        "train_df,valid_df = train_test_split(train_df, test_size=0.1, random_state=RANDOM_SEED,shuffle=True)\n",
        "train_df = train_df.reset_index(drop=True)\n",
        "test_df = test_df.reset_index(drop=True)\n",
        "valid_df = valid_df.reset_index(drop=True)\n",
        "train_df.shape, valid_df.shape, test_df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4368, 5), (486, 5), (540, 5))"
            ]
          },
          "metadata": {},
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7Cn37Fip8Ei",
        "outputId": "f83bb56e-d40b-48e1-81a2-6eddb11d6bf3"
      },
      "source": [
        "from transformers import AlbertTokenizer\n",
        "\n",
        "tokenizer = AlbertTokenizer.from_pretrained(model_name)\n",
        "train_encodings = tokenizer(train_df.Clean_Body.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('train tokenized')\n",
        "test_encodings = tokenizer(test_df.Clean_Body.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('test tokenized')\n",
        "valid_encodings = tokenizer(valid_df.Clean_Body.tolist(), max_length=max_len, truncation=True, padding=True)\n",
        "print('valid tokenized')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train tokenized\n",
            "test tokenized\n",
            "valid tokenized\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiQG1Us4p8FY",
        "outputId": "328c7c0e-39b6-43b4-ae0c-84c358eb9591"
      },
      "source": [
        "from transformers import AutoConfig\n",
        "\n",
        "# create a dict for classes\n",
        "label2id = {label: i for i, label in enumerate(range(class_number))}\n",
        "id2label = {v: k for k, v in label2id.items()}\n",
        "config = AutoConfig.from_pretrained(model_name,**{'label2id': label2id, 'id2label': id2label})\n",
        "\n",
        "print(f'label2id: {label2id}')\n",
        "print(f'id2label: {id2label}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label2id: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n",
            "id2label: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrUKvxiIp8Ob"
      },
      "source": [
        "import torch\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AlbertForSequenceClassification, AutoModel\n",
        "# set device\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvjC0YGhqQDp"
      },
      "source": [
        "class DigiMagDs(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "# create datasets\n",
        "train_ds = DigiMagDs(train_encodings, train_df.Labels)\n",
        "valid_ds = DigiMagDs(valid_encodings, valid_df.Labels)\n",
        "test_ds = DigiMagDs(test_encodings, test_df.Labels)\n",
        "\n",
        "\n",
        "# create Dataloders\n",
        "# train_ds = PandasDataset(train_ds)\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# valid_ds = PandasDataset(valid_ds)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "# test_ds = PandasDataset(test_ds)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZeDCpPytbPi",
        "outputId": "03f5d471-8c3a-43bc-d9da-afabe34270c3"
      },
      "source": [
        "model = AlbertForSequenceClassification.from_pretrained(model_name, config=config)\n",
        "model.to(device)\n",
        "# AdamW is just adam with fixing on weight decay (don't worry about it)\n",
        "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.001)\n",
        "num_epoch = 6\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, num_epoch *len(train_dl))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at HooshvareLab/albert-fa-zwnj-base-v2 were not used when initializing AlbertForSequenceClassification: ['predictions.decoder.bias', 'predictions.decoder.weight', 'predictions.dense.weight', 'predictions.LayerNorm.bias', 'predictions.bias', 'predictions.dense.bias', 'predictions.LayerNorm.weight']\n",
            "- This IS expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing AlbertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at HooshvareLab/albert-fa-zwnj-base-v2 and are newly initialized: ['albert.pooler.weight', 'classifier.weight', 'classifier.bias', 'albert.pooler.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bRitf2NtiF8",
        "outputId": "d5a95745-6a45-431d-d995-061e252f41a1"
      },
      "source": [
        "trainer = TorchTrainer(model, train_dl, valid_dl, test_dl, optimizer=optimizer, scheduler = scheduler)\n",
        "trainer.fit(num_epochs=num_epoch)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 1.6461\n",
            "  Valid_Step: 15/15 | runing_loss: 1.5578\n",
            " Metrics: | train_acc: 0.392 | valid_acc: 0.426 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n",
            "Epoch  2/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 1.4026\n",
            "  Valid_Step: 15/15 | runing_loss: 1.3614\n",
            " Metrics: | train_acc: 0.502 | valid_acc: 0.533 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n",
            "Epoch  3/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 1.1018\n",
            "  Valid_Step: 15/15 | runing_loss: 1.2358\n",
            " Metrics: | train_acc: 0.629 | valid_acc: 0.576 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n",
            "Epoch  4/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 0.7139\n",
            "  Valid_Step: 15/15 | runing_loss: 1.1800\n",
            " Metrics: | train_acc: 0.765 | valid_acc: 0.628 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n",
            "Epoch  5/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 0.3800\n",
            "  Valid_Step: 15/15 | runing_loss: 1.2141\n",
            " Metrics: | train_acc: 0.893 | valid_acc: 0.654 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n",
            "Epoch  6/ 6\n",
            "--------------------\n",
            "  Train_Step: 137/136 | runing_loss: 0.2358\n",
            "  Valid_Step: 15/15 | runing_loss: 1.1684\n",
            " Metrics: | train_acc: 0.942 | valid_acc: 0.658 |\n",
            "\n",
            "  Epoch complete in: 3m 1s \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C5tfsREwT_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e621eef-a8a3-4c5a-d453-62ccb67ed504"
      },
      "source": [
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "Accuracy, y_pred, y_true = trainer.test_model()\n",
        " \n",
        "print(Accuracy)\n",
        "print(precision_recall_fscore_support(y_true, y_pred, average='micro'))\n",
        "print(precision_recall_fscore_support(y_true, y_pred, average='macro'))\n",
        "print(precision_recall_fscore_support(y_true, y_pred, average='weighted'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Valid_Step: 16/16 | runing_loss: 1.2297tensor([0.6389])\n",
            "(0.6388888888888888, 0.6388888888888888, 0.6388888888888888, None)\n",
            "(0.5447158493503664, 0.5260592875374054, 0.5328243151813717, None)\n",
            "(0.6364853755806347, 0.6388888888888888, 0.636712359737715, None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iWMXJ5nHunyB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJfeoKVox3tM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFpNBggHzo_s"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SkdXYwbl3HOz",
        "outputId": "e592ee78-c024-441c-b4b8-9f9197226bef"
      },
      "source": [
        "Accuracy, y_pred, y_true = trainer.test_model_probs()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "  Valid_Step: 16/16 | runing_loss: 1.2269"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PBFTLnxVL5fm",
        "outputId": "1064f3f9-9fea-4509-9e21-e1f638007de4"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "from numpy import arange\n",
        "\n",
        "thresholds = np.arange(0.1,0.5,0.01)\n",
        "probs = y_pred\n",
        "def to_labels(pos_probs, threshold):\n",
        "\treturn (pos_probs >= threshold).astype('int')\n",
        " \n",
        "scores = [f1_score(y_true, to_labels(probs, t), average='weighted') for t in thresholds]\n",
        "# get best threshold\n",
        "ix = argmax(scores)\n",
        "print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Threshold=0.480, F-Score=0.09675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20eqSA8iNQBe",
        "outputId": "b645e613-2ec5-4add-aa2a-fd77789e84bb"
      },
      "source": [
        "scores[ix]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.09675093783620917"
            ]
          },
          "metadata": {},
          "execution_count": 250
        }
      ]
    }
  ]
}